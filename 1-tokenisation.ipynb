{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenisation\n",
    "\n",
    "In deze notebook laden we de commentaren van de enquête in en passen we tokenisation toe: het splitsen van de tekst in aparte woorden/entiteiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports\n",
    "\n",
    "We laden uitbreidingen in die we nodig hebben om de dataset in te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy_download import load_spacy\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset inladen\n",
    "\n",
    "We laden de dataset in en tonen een preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_anon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2_1</th>\n",
       "      <th>Q2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Q11num</th>\n",
       "      <th>Q11numopp</th>\n",
       "      <th>Q7binary</th>\n",
       "      <th>Q13dialoog</th>\n",
       "      <th>Q13educatief</th>\n",
       "      <th>Q13elitair</th>\n",
       "      <th>Q13ouderwets</th>\n",
       "      <th>Q13reflectie</th>\n",
       "      <th>Q13fundament</th>\n",
       "      <th>Q13anders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1030</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 01:49:27</td>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>patricia de martelaere</td>\n",
       "      <td>connie palmen - de vriendschap</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>een aanzet tot dialoog over literatuur en lite...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een aanzet tot reflectie en een bron voor debat</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>252</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:05:02</td>\n",
       "      <td>R_1I6pSyFmgXFtRjH</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>De Laatste Dichters - Christine Otten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>651</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:05:56</td>\n",
       "      <td>R_2OVxUcnSQ8BFaqa</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>Gangreen 1- Jef Geeraerts</td>\n",
       "      <td>De Zondvloed - Jeroen Brouwers</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>een aanzet tot dialoog over literatuur en lite...</td>\n",
       "      <td>een educatief instrument</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1901</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:31:21</td>\n",
       "      <td>R_2b0CIkQZZJq6ey6</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>De Kapellekensbaan - Louis Paul Boon</td>\n",
       "      <td>Max Havelaar - Multatuli</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>elitair en niet-inclusief</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>440</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 03:15:49</td>\n",
       "      <td>R_6M3bVJZ8xxgVL5T</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>Van den vos Reynaerde</td>\n",
       "      <td>Max Havelaar</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Progress  Duration (in seconds)  Finished         RecordedDate  \\\n",
       "0           1       100                   1030      True  2022-05-19 01:49:27   \n",
       "1           2       100                    252      True  2022-05-19 02:05:02   \n",
       "2           3       100                    651      True  2022-05-19 02:05:56   \n",
       "3           4       100                   1901      True  2022-05-19 02:31:21   \n",
       "4           5       100                    440      True  2022-05-19 03:15:49   \n",
       "\n",
       "          ResponseId UserLanguage  \\\n",
       "0  R_2wjiSHblELDyZMY           NL   \n",
       "1  R_1I6pSyFmgXFtRjH           NL   \n",
       "2  R_2OVxUcnSQ8BFaqa           NL   \n",
       "3  R_2b0CIkQZZJq6ey6           NL   \n",
       "4  R_6M3bVJZ8xxgVL5T           NL   \n",
       "\n",
       "                                                  Q1  \\\n",
       "0  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "1  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "2  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "3  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "4  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "\n",
       "                                    Q2_1                            Q2_2  ...  \\\n",
       "0                 patricia de martelaere  connie palmen - de vriendschap  ...   \n",
       "1  De Laatste Dichters - Christine Otten                             NaN  ...   \n",
       "2              Gangreen 1- Jef Geeraerts  De Zondvloed - Jeroen Brouwers  ...   \n",
       "3   De Kapellekensbaan - Louis Paul Boon        Max Havelaar - Multatuli  ...   \n",
       "4                  Van den vos Reynaerde                    Max Havelaar  ...   \n",
       "\n",
       "  Q11num Q11numopp Q7binary  \\\n",
       "0    2.0       0.0  Analoog   \n",
       "1    2.0       0.0      NaN   \n",
       "2    2.0       0.0  Analoog   \n",
       "3    2.0       0.0  Analoog   \n",
       "4    1.0       1.0  Analoog   \n",
       "\n",
       "                                          Q13dialoog  \\\n",
       "0  een aanzet tot dialoog over literatuur en lite...   \n",
       "1                                                  0   \n",
       "2  een aanzet tot dialoog over literatuur en lite...   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "               Q13educatief                 Q13elitair Q13ouderwets  \\\n",
       "0                         0                          0            0   \n",
       "1                         0                          0            0   \n",
       "2  een educatief instrument                          0            0   \n",
       "3                         0  elitair en niet-inclusief            0   \n",
       "4                         0                          0            0   \n",
       "\n",
       "                                      Q13reflectie  \\\n",
       "0  een aanzet tot reflectie en een bron voor debat   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "                                        Q13fundament Q13anders  \n",
       "0  een fundament van een collectief cultureel geh...         0  \n",
       "1  een fundament van een collectief cultureel geh...         0  \n",
       "2  een fundament van een collectief cultureel geh...         0  \n",
       "3  een fundament van een collectief cultureel geh...         0  \n",
       "4  een fundament van een collectief cultureel geh...         0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Tokenisation\n",
    "\n",
    "[spaCy](https://spacy.io/) is een bekende package om tekst te parsen en verwerken. Met spaCy kan je héél veel (POS-taggen, tokenisen, lemmatisen, named entity recognition). Wij gaan gewoon alles opsplitsen in woordjes.\n",
    "\n",
    "Ik heb [load_spacy](https://github.com/BramVanroy/spacy_download) van collega Bram Vanroy gebruikt, omdat dit automatisch ook het model downloadt als je het nog niet hebt. Verder werkt alles zoals je zou verwachten van spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.nl.Dutch at 0x1f033dca650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = load_spacy(\"nl_core_news_lg\", exclude=[\"parser\", \"tagger\"])\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De voorgaande code werd aangepast om voor iedere open vraag een nieuwe output-file te maken waarin de open antwoorden gelemmatiseerd wordt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze lijn sorteert alle toelichtingsvragen uit de dataset en creëert een variabele per open vraag.\n",
    "ELAB = {question for question in df if \"ELAB\" in question}\n",
    "ELAB.add(\"QPERS_IDEAS\")\n",
    "ELAB.add(\"QPERS_COMPLAIN\")\n",
    "# De loop wordt gebruikt om iedere vraag apart te analyseren.\n",
    "for question in ELAB:\n",
    "    # Door de rijen in de loop te steken, worden de rijen per vraag herschreven.\n",
    "    rows = []\n",
    "    # Hier worden steeds per vraag de niet-beantwoorde vragen eruit gefilterd.\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row[str(question)]):\n",
    "            continue\n",
    "        # De beantwoorde vragen worden via deze code gelemmatiseerd waarbij een identifyer, de gebruiker, de zin,\n",
    "        # het woord, het lemma en de part of speech neergeschreven worden in een dataset.\n",
    "        doc = nlp(row[str(question)])\n",
    "        for sentence_number, sentence in enumerate(doc.sents):\n",
    "            for token_number, token in enumerate (sentence):\n",
    "                if \"ELAB\" in question:\n",
    "                    new_row = { \"identifier\": question.replace('ELAB', '') + row[\"ResponseId\"] + '_' + str(sentence_number) + '_' \n",
    "                               + str(token_number), \"response_id\": row[\"ResponseId\"], \"sentence_number\": sentence_number, \n",
    "                               \"token_number\": token_number, \"token\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_ }\n",
    "                    rows.append(new_row)\n",
    "                elif \"IDEAS\" in question:\n",
    "                    new_row = { \"identifier\": question.replace('QPERS_IDEAS', 'QI_') + row[\"ResponseId\"] + '_' +str(sentence_number) + '_' \n",
    "                               + str(token_number), \"response_id\": row[\"ResponseId\"], \"sentence_number\": sentence_number, \n",
    "                               \"token_number\": token_number, \"token\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_ }\n",
    "                    rows.append(new_row)\n",
    "                elif \"COMPLAIN\" in question:\n",
    "                    new_row = { \"identifier\": question.replace('QPERS_COMPLAIN', 'QC_') + row[\"ResponseId\"] + '_' +str(sentence_number) + '_' \n",
    "                               + str(token_number), \"response_id\": row[\"ResponseId\"], \"sentence_number\": sentence_number, \n",
    "                               \"token_number\": token_number, \"token\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_ }\n",
    "                    rows.append(new_row)\n",
    "                else:\n",
    "                    continue\n",
    "    # De loop maakt verschillende .csv-bestanden aan waarbij de lemmatisering van de vragen respectievelijk opgeslaan worden.\n",
    "    new_df = pd.DataFrame.from_dict(rows) \n",
    "    new_df.to_csv(\"sorted_data/\" + question + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De afzonderlijke documenten worden via deze code gecombineerd, aan de hand van de identifyer (bestaande uit question-number, ResponseId en sentence number) om de vragen uit elkaar te houden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "De canonenquête bevatte 7 toelichtingsvragen en 2 open vragen:\n",
    "- Q9: De aandacht voor de canon in voortgezet/secundair onderwijs.\n",
    "- Q10: Leerlingen in het voortgezet/secundair onderwijs moeten enkele klassiekers lezen.\n",
    "- Q11: Leerlingen in het voortgezet/secundair onderwijs moeten een elementaire kennis aangeboden krijgen van Nederlandstalige literatuurgeschiedenis\n",
    "- Q14: Een Nederlandstalige literaire canon moet streven naar genderdiversiteit.\n",
    "- Q15: Er kunnen meerdere Nederlandstalige literaire canons naast elkaar bestaan.\n",
    "- Q16: Welke teksten uit de voormalige koloniale gebieden zouden in de canon moeten?\n",
    "- Q17: Welke teksten uit de kinder- en jeugdliteratuur zouden in de canon moeten?\n",
    "- QI: Heb je ideeën voor projecten die de canon in de kijker kunnen zetten?\n",
    "- QC: Eventuele opmerkingen\n",
    "\n",
    "Onderstaande code bundelt deze vragen samen waarbij nog steeds iedere vraag, user en sentence number herkenbaar zijn in Combined_OPEN.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'sorted_data/'\n",
    "all_files = os.listdir(p)\n",
    "csv_files = [x for x in all_files if x.endswith('.csv')]\n",
    "df_list = []\n",
    "\n",
    "for csv in csv_files:\n",
    "    f = os.path.join(p, csv)\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "        df_list.append(df)\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep='\\t', encoding='utf-16')\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read file {csv} because of error: {e}\")   \n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file {csv} because of error: {e}\")\n",
    "                              \n",
    "big_df = pd.concat(df_list)\n",
    "big_df_1 = big_df.iloc[: , 1:]\n",
    "\n",
    "big_df_1.to_csv(os.path.join(p, 'Combined_OPEN.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentwaarden toevoegen aan de dataset\n",
    "\n",
    "Via de dataset van het CRR UGent ... (verder uittypen)\n",
    "\n",
    "Via onderstaande worden een aantal kolommen toegevoegd waarin zowel de valentie-, opwinding- als dominantiewaarde voor ieder woord wordt toegevoegd, zowel in de gemiddelde waarde als de standaarddeviatiewaarde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
