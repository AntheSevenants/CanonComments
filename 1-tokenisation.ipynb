{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenisation\n",
    "\n",
    "In deze notebook laden we de commentaren van de enquête in en passen we tokenisation toe: het splitsen van de tekst in aparte woorden/entiteiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports\n",
    "\n",
    "We laden uitbreidingen in die we nodig hebben om de dataset in te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy_download import load_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dataset inladen\n",
    "\n",
    "We laden de dataset in en tonen een preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_anon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2_1</th>\n",
       "      <th>Q2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Q11num</th>\n",
       "      <th>Q11numopp</th>\n",
       "      <th>Q7binary</th>\n",
       "      <th>Q13dialoog</th>\n",
       "      <th>Q13educatief</th>\n",
       "      <th>Q13elitair</th>\n",
       "      <th>Q13ouderwets</th>\n",
       "      <th>Q13reflectie</th>\n",
       "      <th>Q13fundament</th>\n",
       "      <th>Q13anders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1030</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 01:49:27</td>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>patricia de martelaere</td>\n",
       "      <td>connie palmen - de vriendschap</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>een aanzet tot dialoog over literatuur en lite...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een aanzet tot reflectie en een bron voor debat</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>252</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:05:02</td>\n",
       "      <td>R_1I6pSyFmgXFtRjH</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>De Laatste Dichters - Christine Otten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>651</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:05:56</td>\n",
       "      <td>R_2OVxUcnSQ8BFaqa</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>Gangreen 1- Jef Geeraerts</td>\n",
       "      <td>De Zondvloed - Jeroen Brouwers</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>een aanzet tot dialoog over literatuur en lite...</td>\n",
       "      <td>een educatief instrument</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1901</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 02:31:21</td>\n",
       "      <td>R_2b0CIkQZZJq6ey6</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>De Kapellekensbaan - Louis Paul Boon</td>\n",
       "      <td>Max Havelaar - Multatuli</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>elitair en niet-inclusief</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>440</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-05-19 03:15:49</td>\n",
       "      <td>R_6M3bVJZ8xxgVL5T</td>\n",
       "      <td>NL</td>\n",
       "      <td>Ik ben zestien of ouder, besef dat mijn gegeve...</td>\n",
       "      <td>Van den vos Reynaerde</td>\n",
       "      <td>Max Havelaar</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Analoog</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>een fundament van een collectief cultureel geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Progress  Duration (in seconds)  Finished         RecordedDate  \\\n",
       "0           1       100                   1030      True  2022-05-19 01:49:27   \n",
       "1           2       100                    252      True  2022-05-19 02:05:02   \n",
       "2           3       100                    651      True  2022-05-19 02:05:56   \n",
       "3           4       100                   1901      True  2022-05-19 02:31:21   \n",
       "4           5       100                    440      True  2022-05-19 03:15:49   \n",
       "\n",
       "          ResponseId UserLanguage  \\\n",
       "0  R_2wjiSHblELDyZMY           NL   \n",
       "1  R_1I6pSyFmgXFtRjH           NL   \n",
       "2  R_2OVxUcnSQ8BFaqa           NL   \n",
       "3  R_2b0CIkQZZJq6ey6           NL   \n",
       "4  R_6M3bVJZ8xxgVL5T           NL   \n",
       "\n",
       "                                                  Q1  \\\n",
       "0  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "1  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "2  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "3  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "4  Ik ben zestien of ouder, besef dat mijn gegeve...   \n",
       "\n",
       "                                    Q2_1                            Q2_2  ...  \\\n",
       "0                 patricia de martelaere  connie palmen - de vriendschap  ...   \n",
       "1  De Laatste Dichters - Christine Otten                             NaN  ...   \n",
       "2              Gangreen 1- Jef Geeraerts  De Zondvloed - Jeroen Brouwers  ...   \n",
       "3   De Kapellekensbaan - Louis Paul Boon        Max Havelaar - Multatuli  ...   \n",
       "4                  Van den vos Reynaerde                    Max Havelaar  ...   \n",
       "\n",
       "  Q11num Q11numopp Q7binary  \\\n",
       "0    2.0       0.0  Analoog   \n",
       "1    2.0       0.0      NaN   \n",
       "2    2.0       0.0  Analoog   \n",
       "3    2.0       0.0  Analoog   \n",
       "4    1.0       1.0  Analoog   \n",
       "\n",
       "                                          Q13dialoog  \\\n",
       "0  een aanzet tot dialoog over literatuur en lite...   \n",
       "1                                                  0   \n",
       "2  een aanzet tot dialoog over literatuur en lite...   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "               Q13educatief                 Q13elitair Q13ouderwets  \\\n",
       "0                         0                          0            0   \n",
       "1                         0                          0            0   \n",
       "2  een educatief instrument                          0            0   \n",
       "3                         0  elitair en niet-inclusief            0   \n",
       "4                         0                          0            0   \n",
       "\n",
       "                                      Q13reflectie  \\\n",
       "0  een aanzet tot reflectie en een bron voor debat   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "                                        Q13fundament Q13anders  \n",
       "0  een fundament van een collectief cultureel geh...         0  \n",
       "1  een fundament van een collectief cultureel geh...         0  \n",
       "2  een fundament van een collectief cultureel geh...         0  \n",
       "3  een fundament van een collectief cultureel geh...         0  \n",
       "4  een fundament van een collectief cultureel geh...         0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Tokenisation\n",
    "\n",
    "[spaCy](https://spacy.io/) is een bekende package om tekst te parsen en verwerken. Met spaCy kan je héél veel (POS-taggen, tokenisen, lemmatisen, named entity recognition). Wij gaan gewoon alles opsplitsen in woordjes.\n",
    "\n",
    "Ik heb [load_spacy](https://github.com/BramVanroy/spacy_download) van collega Bram Vanroy gebruikt, omdat dit automatisch ook het model downloadt als je het nog niet hebt. Verder werkt alles zoals je zou verwachten van spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.nl.Dutch at 0x1f02413af10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = load_spacy(\"nl_core_news_lg\", exclude=[\"parser\", \"tagger\"])\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik toon hoe je een zin kunt tokeniseren met spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Freek Freek PROPN\n",
      "0 Van Van PROPN\n",
      "0 de de PROPN\n",
      "0 Velde Velde PROPN\n",
      "0 neemt toenemen VERB\n",
      "0 geen geen DET\n",
      "0 deel deel NOUN\n",
      "0 aan aan ADP\n",
      "0 de de DET\n",
      "0 fantastische fantastisch ADJ\n",
      "0 taalkundequiz taalkundequiz NOUN\n",
      "0 . . PUNCT\n",
      "1 Ik ik PRON\n",
      "1 speel speel VERB\n",
      "1 graag graag ADV\n",
      "1 Minecraft Minecraft PROPN\n",
      "1 . . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Freek Van de Velde neemt geen deel aan de fantastische taalkundequiz. Ik speel graag Minecraft.\")\n",
    "for sentence_number, sentence in enumerate(doc.sents):\n",
    "    for token in sentence:\n",
    "        print(sentence_number, token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu is het de bedoeling dat we hetzelfde doen met de commentaren uit de enquête. Ik geef een voorzet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "# We itereren over elke rij van de dataset\n",
    "for index, row in df.iterrows():\n",
    "    # pd.isnull wordt gebruikt om lege rijen weg te laten.\n",
    "    if pd.isnull(row[\"Q9_ELAB\"]):\n",
    "        continue\n",
    "    \n",
    "    #Iedere zin per respondent wordt opgesplitst en benummerd.\n",
    "    doc = nlp(row[\"Q9_ELAB\"])\n",
    "    for sentence_number, sentence in enumerate(doc.sents):\n",
    "        for token in sentence:\n",
    "    # Je kunt een kolom opvragen door die te indexeren\n",
    "    # Hier worden de zinnen opgesplitst per respondent.\n",
    "            new_row = { \"response_id\": row[\"ResponseId\"], \"sentence_no\": sentence_number, \"token\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_ }\n",
    "            rows.append(new_row)\n",
    "\n",
    "    # Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen voor elke token een aparte rij in onze dataset. Zoiets:\n",
    "\n",
    "|sentence_no|token|lemma|pos|\n",
    "|---|---|---|---|\n",
    "|0|Freek|Freek|PROPN|\n",
    "|0|neemt|nemen|VERB|\n",
    "|0|deel|deel|NOUN|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kunt als volgt een eigen dataset maken:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ziet hoe je deze snippet in de loop hierboven kunt zetten om zo een nieuwe dataset te maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>0</td>\n",
       "      <td>zonder</td>\n",
       "      <td>zonder</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>0</td>\n",
       "      <td>canon</td>\n",
       "      <td>canon</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>0</td>\n",
       "      <td>kan</td>\n",
       "      <td>kunnen</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>0</td>\n",
       "      <td>je</td>\n",
       "      <td>je</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_2wjiSHblELDyZMY</td>\n",
       "      <td>0</td>\n",
       "      <td>niks</td>\n",
       "      <td>niks</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         response_id  sentence_no   token   lemma   pos\n",
       "0  R_2wjiSHblELDyZMY            0  zonder  zonder   ADP\n",
       "1  R_2wjiSHblELDyZMY            0   canon   canon  NOUN\n",
       "2  R_2wjiSHblELDyZMY            0     kan  kunnen   AUX\n",
       "3  R_2wjiSHblELDyZMY            0      je      je  PRON\n",
       "4  R_2wjiSHblELDyZMY            0    niks    niks  PRON"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame.from_dict(rows)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De voorgaande code werd aangepast om voor iedere open vraag een nieuwe output-file te maken waarin de open antwoorden gelemmatiseerd wordt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze lijn sorteert alle open vragen uit de dataset en creëert een variabele per open vraag.\n",
    "ELAB = {question for question in df if \"ELAB\" in question}\n",
    "# De loop wordt gebruikt om iedere vraag apart te analyseren.\n",
    "for question in ELAB:\n",
    "    #Door de rijen in de loop te steken, worden de rijen per vraag herschreven.\n",
    "    rows = []\n",
    "    # Hier worden steeds per vraag de niet-beantwoorde vragen eruit gefilterd.\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row[str(question)]):\n",
    "            continue\n",
    "        # De beantwoorde vragen worden via deze code gelemmatiseerd waarbij de gebruiker, de zin,\n",
    "        # het woord, het lemma en de part of speech neergeschreven worden in een dataset.\n",
    "        doc = nlp(row[str(question)])\n",
    "        for sentence_number, sentence in enumerate(doc.sents):\n",
    "            for token in sentence:\n",
    "                new_row = { \"response_id\": row[\"ResponseId\"], \"sentence_no\": sentence_number, \"token\": token.text, \"lemma\": token.lemma_, \"pos\": token.pos_ }\n",
    "                rows.append(new_row)\n",
    "    # De loop maakt verschillende .csv-bestanden aan waarbij de lemmatisering van de vragen respectievelijk opgeslaan worden.\n",
    "    new_df = pd.DataFrame.from_dict(rows) \n",
    "    new_df.to_csv(\"sorted_data/\" + question + \".csv\")\n",
    "    \n",
    "    # Tokenisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
